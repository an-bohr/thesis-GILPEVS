{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipympl\n",
    "# %matplotlib ipympl\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot([1, 2, 3], [1, 4, 9])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred segmentation volume size: torch.Size([284, 327, 243])\n",
      "Epoch 1/10: 100%|█████████████████████████████| 20/20 [01:11<00:00,  3.57s/case]\n",
      "[Epoch 1/10] Loss = 352.8132 (Recon: 352.8132, KL: 0.0000) | Time: 71.45s, Estimated remaining: 643.02s\n",
      "Epoch 2/10: 100%|█████████████████████████████| 20/20 [01:09<00:00,  3.48s/case]\n",
      "[Epoch 2/10] Loss = 64.1649 (Recon: 64.1649, KL: 0.0000) | Time: 69.61s, Estimated remaining: 556.91s\n",
      "Epoch 3/10: 100%|█████████████████████████████| 20/20 [01:09<00:00,  3.48s/case]\n",
      "[Epoch 3/10] Loss = 25.0091 (Recon: 25.0091, KL: 0.0000) | Time: 69.60s, Estimated remaining: 487.20s\n",
      "Epoch 4/10: 100%|█████████████████████████████| 20/20 [01:11<00:00,  3.56s/case]\n",
      "[Epoch 4/10] Loss = 11.0542 (Recon: 11.0542, KL: 0.0003) | Time: 71.11s, Estimated remaining: 426.69s\n",
      "Epoch 5/10: 100%|█████████████████████████████| 20/20 [01:11<00:00,  3.55s/case]\n",
      "[Epoch 5/10] Loss = 9.1003 (Recon: 9.1003, KL: 0.0002) | Time: 71.04s, Estimated remaining: 355.22s\n",
      "Epoch 6/10: 100%|█████████████████████████████| 20/20 [01:12<00:00,  3.61s/case]\n",
      "[Epoch 6/10] Loss = 7.8107 (Recon: 7.8107, KL: 0.0001) | Time: 72.23s, Estimated remaining: 288.93s\n",
      "Epoch 7/10: 100%|█████████████████████████████| 20/20 [01:11<00:00,  3.59s/case]\n",
      "[Epoch 7/10] Loss = 7.3194 (Recon: 7.3194, KL: 0.0001) | Time: 71.77s, Estimated remaining: 215.31s\n",
      "Epoch 8/10: 100%|█████████████████████████████| 20/20 [01:10<00:00,  3.55s/case]\n",
      "[Epoch 8/10] Loss = 7.0398 (Recon: 7.0398, KL: 0.0002) | Time: 70.93s, Estimated remaining: 141.85s\n",
      "Epoch 9/10: 100%|█████████████████████████████| 20/20 [01:12<00:00,  3.62s/case]\n",
      "[Epoch 9/10] Loss = 6.7043 (Recon: 6.7043, KL: 0.0002) | Time: 72.41s, Estimated remaining: 72.41s\n",
      "Epoch 10/10: 100%|████████████████████████████| 20/20 [01:11<00:00,  3.58s/case]\n",
      "[Epoch 10/10] Loss = 6.4158 (Recon: 6.4158, KL: 0.0003) | Time: 71.57s, Estimated remaining: 0.00s\n",
      "Finished training the geometric model! Loss curves saved as 'loss_curves.png'.\n",
      "Geometric model weights saved as 'geo_model.pth'.\n",
      "Using imperfect segmentation from inference folder: TopCoW/gt_train/topcow_ct_001.nii.gz\n",
      "Saved SDF comparison plot as 'sdf_comparison.png'\n",
      "Saved latent distribution plot as 'latent_distribution.png'\n",
      "Full SDF volume saved as full_sdf_volume.nii.gz\n",
      "Saved full SDF volume as 'full_sdf_volume.nii.gz'\n",
      "Warning: Desired iso_level not in range [-5.8845, -0.0128]. Using iso_level=-2.9487\n",
      "Reconstructed mesh saved as reconstructed_mesh.obj\n",
      "Skipping refinement since no CT was provided.\n"
     ]
    }
   ],
   "source": [
    "!python main.py --data_folder_seg TopCoW/gt_train --data_folder_ct TopCoW/images_train --infer_folder TopCoW/gt_train --epochs_geo 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic mask saved as synthetic_mask.nii.gz\n",
      "Using synthetic segmentation mask for testing.\n",
      "Inferred segmentation volume size: torch.Size([128, 128, 128])\n",
      "Epoch 1/10: 100%|█████████████████████████████| 10/10 [00:59<00:00,  5.91s/case]\n",
      "[Epoch 1/10] Loss = 4741485.9062 (Recon: 4741485.9062, KL: 0.0000) | Time: 59.12s, Estimated remaining: 532.05s\n",
      "Epoch 2/10: 100%|█████████████████████████████| 10/10 [01:01<00:00,  6.12s/case]\n",
      "[Epoch 2/10] Loss = 1950717.8750 (Recon: 1950717.8750, KL: 0.0000) | Time: 61.18s, Estimated remaining: 489.44s\n",
      "Epoch 3/10: 100%|█████████████████████████████| 10/10 [01:01<00:00,  6.19s/case]\n",
      "[Epoch 3/10] Loss = 785149.7312 (Recon: 785149.7312, KL: 0.0000) | Time: 61.90s, Estimated remaining: 433.32s\n",
      "Epoch 4/10: 100%|█████████████████████████████| 10/10 [01:06<00:00,  6.64s/case]\n",
      "[Epoch 4/10] Loss = 514728.2500 (Recon: 514728.2500, KL: 0.0000) | Time: 66.41s, Estimated remaining: 398.47s\n",
      "Epoch 5/10: 100%|█████████████████████████████| 10/10 [00:59<00:00,  5.95s/case]\n",
      "[Epoch 5/10] Loss = 381442.3016 (Recon: 381442.3016, KL: 0.0000) | Time: 59.46s, Estimated remaining: 297.31s\n",
      "Epoch 6/10: 100%|█████████████████████████████| 10/10 [00:59<00:00,  5.92s/case]\n",
      "[Epoch 6/10] Loss = 272536.0246 (Recon: 272536.0246, KL: 0.0000) | Time: 59.21s, Estimated remaining: 236.86s\n",
      "Epoch 7/10: 100%|█████████████████████████████| 10/10 [00:59<00:00,  5.98s/case]\n",
      "[Epoch 7/10] Loss = 213381.4844 (Recon: 213381.4844, KL: 0.0001) | Time: 59.80s, Estimated remaining: 179.39s\n",
      "Epoch 8/10: 100%|█████████████████████████████| 10/10 [00:59<00:00,  5.96s/case]\n",
      "[Epoch 8/10] Loss = 154784.4328 (Recon: 154784.4328, KL: 0.0001) | Time: 59.55s, Estimated remaining: 119.11s\n",
      "Epoch 9/10: 100%|█████████████████████████████| 10/10 [01:00<00:00,  6.02s/case]\n",
      "[Epoch 9/10] Loss = 32553.0595 (Recon: 32553.0595, KL: 0.0003) | Time: 60.21s, Estimated remaining: 60.21s\n",
      "Epoch 10/10: 100%|████████████████████████████| 10/10 [01:00<00:00,  6.01s/case]\n",
      "[Epoch 10/10] Loss = 2827.6928 (Recon: 2827.6928, KL: 0.0010) | Time: 60.06s, Estimated remaining: 0.00s\n",
      "Finished training the geometric model! Loss curves saved as 'loss_curves.png'.\n",
      "Geometric model weights saved as 'geo_model.pth'.\n",
      "Using segmentation file for inference (no infer_folder provided).\n",
      "Saved SDF comparison plot as 'sdf_comparison.png'\n",
      "Saved latent distribution plot as 'latent_distribution.png'\n",
      "Full SDF volume saved as full_sdf_volume.nii.gz\n",
      "Saved full SDF volume as 'full_sdf_volume.nii.gz'\n",
      "Predicted SDF volume stats: -8.439923 0.8521951\n",
      "Reconstructed mesh saved as reconstructed_mesh.obj\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucasp/thesis/main.py\", line 282, in <module>\n",
      "    main()\n",
      "  File \"/home/lucasp/thesis/main.py\", line 279, in main\n",
      "    inference_dummy(geo_model, refiner, new_seg, new_ct, recon_resolution=mesh_res, device=device)\n",
      "  File \"/home/lucasp/thesis/main.py\", line 185, in inference_dummy\n",
      "    refiner_input = torch.cat([ct_vol, seg_vol, uncertainty_map], dim=1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 284 but got size 128 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "# To test with syntehtic mask:\n",
    "!python main.py --data_folder_seg TopCoW/gt_train --data_folder_ct TopCoW/images_train --epochs_geo 10 --create_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic mask saved as synthetic_mask.nii.gz\n",
      "Using synthetic segmentation mask for testing.\n",
      "Inferred segmentation volume size: torch.Size([128, 128, 128])\n",
      "/home/lucasp/thesis/main.py:245: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  geo_model.load_state_dict(torch.load(args.load_weights))\n",
      "Loaded geometric model weights from geo_model_trained_on_sphere.pth\n",
      "Using segmentation file for inference (no infer_folder provided).\n",
      "Saved SDF comparison plot as 'sdf_comparison.png'\n",
      "Saved latent distribution plot as 'latent_distribution.png'\n",
      "Full SDF volume saved as full_sdf_volume.nii.gz\n",
      "Saved full SDF volume as 'full_sdf_volume.nii.gz'\n",
      "Predicted SDF volume stats: -2.644587 1.9661741\n",
      "Reconstructed mesh saved as reconstructed_mesh.obj\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucasp/thesis/main.py\", line 282, in <module>\n",
      "    main()\n",
      "  File \"/home/lucasp/thesis/main.py\", line 279, in main\n",
      "    inference_dummy(geo_model, refiner, new_seg, new_ct, recon_resolution=mesh_res, device=device)\n",
      "  File \"/home/lucasp/thesis/main.py\", line 185, in inference_dummy\n",
      "    refiner_input = torch.cat([ct_vol, seg_vol, uncertainty_map], dim=1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 284 but got size 128 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "# Testing inference on sphere:\n",
    "!python main.py --data_folder_seg TopCoW/gt_train --data_folder_ct TopCoW/images_train --epochs_geo 10 --create_synthetic --load_weights geo_model_trained_on_sphere.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred segmentation volume size: torch.Size([284, 327, 243])\n",
      "/home/lucasp/thesis/main.py:266: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  geo_model.load_state_dict(torch.load(args.load_weights))\n",
      "Loaded geometric model weights from geo_model.pth\n",
      "Using imperfect segmentation from inference folder: TopCoW/gt_train/topcow_ct_001.nii.gz\n",
      "Saved SDF comparison plot as 'sdf_comparison.png'\n",
      "Saved latent distribution plot as 'latent_distribution.png'\n",
      "Latent optimization iteration 10/50, Loss: 17.1853\n",
      "Latent optimization iteration 20/50, Loss: 15.0210\n",
      "Latent optimization iteration 30/50, Loss: 13.2925\n",
      "Latent optimization iteration 40/50, Loss: 11.9247\n",
      "Latent optimization iteration 50/50, Loss: 10.8398\n",
      "Warning: Desired iso_level not in range [-9.3717, -2.4193]. Using iso_level=-5.8955\n",
      "Reconstructed mesh saved as reconstructed_mesh.obj\n",
      "Skipping refinement since no CT was provided.\n"
     ]
    }
   ],
   "source": [
    "!python main.py --data_folder_seg TopCoW/gt_train --data_folder_ct TopCoW/images_train --infer_folder TopCoW/gt_train --epochs_geo 10 --load_weights geo_model.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
